import streamlit as st
import asyncio
import sys
import subprocess
import pandas as pd
import re

# --- ãƒ–ãƒ©ã‚¦ã‚¶ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å‡¦ç† ---
def install_playwright_browser():
    try:
        import os
        subprocess.run([sys.executable, "-m", "playwright", "install", "chromium"], check=True)
    except Exception as e:
        print(f"Error installing browser: {e}")

install_playwright_browser()

from playwright.async_api import async_playwright
from deep_translator import GoogleTranslator

# --- Windowså¯¾ç­– ---
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ– ---
if 'scraped_data_list' not in st.session_state:
    st.session_state.scraped_data_list = []
if 'current_raw_data' not in st.session_state:
    st.session_state.current_raw_data = None # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç›´å¾Œã®ç”Ÿãƒ‡ãƒ¼ã‚¿
if 'selected_image_indices' not in st.session_state:
    st.session_state.selected_image_indices = []

# --- ã‚«ãƒ†ã‚´ãƒªãƒ¼å®šç¾© (ã“ã“ã§Item Specificsã‚’ç®¡ç†) ---
CATEGORY_CONFIG = {
    "Collectibles (Figures/Toys)": {
        "id": "246",
        "specifics": ["Brand", "Franchise", "Character", "Type", "Year"]
    },
    "Clothing/Shoes (Sneakers)": {
        "id": "15709", # Men's Shoes
        "specifics": ["Brand", "US Shoe Size", "Department", "Style", "Color", "Upper Material", "Type"]
    },
    "Clothing (Apparel)": {
        "id": "1059", # Men's Clothing
        "specifics": ["Brand", "Size", "Size Type", "Department", "Color", "Type", "Style"]
    },
    "Cameras & Photo": {
        "id": "31388", # Digital Cameras
        "specifics": ["Brand", "Model", "Type", "Maximum Resolution", "Series"]
    },
    "Watches": {
        "id": "31387",
        "specifics": ["Brand", "Department", "Type", "Model", "Movement", "Dial Color"]
    },
    "Fishing (Reels/Rods)": {
        "id": "1492",
        "specifics": ["Brand", "Reel Type", "Hand Retrieve", "Fish Species", "Model"]
    },
    "Video Games": {
        "id": "139973",
        "specifics": ["Platform", "Game Name", "Publisher", "Region Code", "Rating"]
    },
    "Others (Generic)": {
        "id": "1",
        "specifics": ["Brand", "MPN", "Type", "Model"]
    }
}

# --- å…±é€šé–¢æ•° ---
def translate_text(text):
    try:
        if not text or text == "å–å¾—å¤±æ•—": return ""
        return GoogleTranslator(source='ja', target='en').translate(text)
    except:
        return text

# --- ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ­ã‚¸ãƒƒã‚¯ (å‰å›åŒæ§˜ã®å¼·åŠ›ç‰ˆ) ---
async def scrape_data(url):
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True, args=['--no-sandbox', '--disable-setuid-sandbox'])
        context = await browser.new_context(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36")
        page = await context.new_page()
        
        try:
            await page.goto(url, timeout=60000)
            try: await page.wait_for_load_state("domcontentloaded", timeout=10000)
            except: pass
            await page.wait_for_timeout(3000)

            # ç”»åƒå–å¾—ãƒ­ã‚¸ãƒƒã‚¯ (ã‚µã‚¤ãƒˆå…±é€š)
            image_urls = []
            
            # 1. Amazon/Mercari/Yahoo/Rakutenã”ã¨ã®ç‰¹æœ‰å‡¦ç†
            if "mercari" in url:
                imgs = await page.locator("img").all()
                for img in imgs:
                    src = await img.get_attribute("src")
                    if src and "static.mercdn.net/item/detail/orig/photos/" in src:
                        image_urls.append(src.split('?')[0])
            
            elif "yahoo" in url:
                imgs = await page.locator("img").all()
                for img in imgs:
                    src = await img.get_attribute("src")
                    if src and "auctions.c.yimg.jp/images/" in src:
                        image_urls.append(src.split('?')[0])
            
            elif "rakuten" in url:
                imgs = await page.locator("img").all()
                for img in imgs:
                    src = await img.get_attribute("src")
                    if src and ("tshop.r10s.jp" in src or "cabinet" in src):
                        if not any(x in src for x in ["logo", "banner", "icon"]):
                            image_urls.append(src.split('?')[0])
            
            elif "amazon" in url:
                imgs = await page.locator("img").all()
                for img in imgs:
                    src = await img.get_attribute("src")
                    if src and ("m.media-amazon.com/images/I/" in src or "ssl-images-amazon.com" in src):
                        image_urls.append(src.split('._')[0] + '.jpg')
            
            # 2. æ±ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ (og:image)
            if not image_urls:
                meta_img = page.locator("meta[property='og:image']")
                if await meta_img.count() > 0:
                    image_urls.append(await meta_img.get_attribute("content"))

            # é‡è¤‡æ’é™¤
            image_urls = list(dict.fromkeys(image_urls))

            # ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
            title = ""
            meta_title = page.locator("meta[property='og:title']")
            if await meta_title.count() > 0:
                title = await meta_title.get_attribute("content")
            if not title:
                if await page.locator("h1").count() > 0:
                    title = await page.locator("h1").first.inner_text()
            
            price = "0"
            # ç°¡æ˜“ä¾¡æ ¼å–å¾—
            body_text = await page.inner_text("body")
            # "Â¥10,000" ã®ã‚ˆã†ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™ç°¡æ˜“æ­£è¦è¡¨ç¾
            prices = re.findall(r'[Â¥ï¿¥][\d,]+', body_text)
            if prices:
                price = prices[0] # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸä¾¡æ ¼ã‚’æ¡ç”¨

            desc = ""
            meta_desc = page.locator("meta[property='og:description']")
            if await meta_desc.count() > 0:
                desc = await meta_desc.get_attribute("content")

            return {"title": title, "price": price, "description": desc, "images": image_urls}

        except Exception as e:
            return {"error": str(e)}
        finally:
            await browser.close()

# --- ç”»é¢UIè¨­å®š ---
st.set_page_config(layout="wide")
st.title("eBayå‡ºå“ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ (æ‰‹å‡ºå“ & CSVå¯¾å¿œç‰ˆ)")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("å…±é€šè¨­å®š")
usd_rate = st.sidebar.number_input("ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆ ($1=Â¥)", value=150)
target_profit = st.sidebar.number_input("ç›®æ¨™åˆ©ç›Š (Â¥)", value=2000)
ebay_fee_rate = 0.15 

# ã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠ
selected_cat_name = st.sidebar.selectbox("å‡ºå“ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’é¸æŠ", list(CATEGORY_CONFIG.keys()))
cat_config = CATEGORY_CONFIG[selected_cat_name]

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ---
url = st.text_input("å•†å“URL (ãƒ¡ãƒ«ã‚«ãƒª, ãƒ¤ãƒ•ã‚ªã‚¯, æ¥½å¤©, Amazon)", "")

if st.button("æƒ…å ±ã‚’å–å¾—ã™ã‚‹"):
    if not url:
        st.warning("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        with st.spinner('è§£æä¸­...'):
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            raw_data = loop.run_until_complete(scrape_data(url))
            loop.close()
            
            if "error" in raw_data:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {raw_data['error']}")
            else:
                # ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.session_state.current_raw_data = raw_data
                # åˆæœŸçŠ¶æ…‹ã§ã¯å…¨ç”»åƒã‚’é¸æŠçŠ¶æ…‹ã«ã™ã‚‹
                st.session_state.selected_image_indices = list(range(len(raw_data['images'])))

# --- ãƒ‡ãƒ¼ã‚¿ç·¨é›†ç”»é¢ ---
if st.session_state.current_raw_data:
    raw = st.session_state.current_raw_data
    
    st.markdown("---")
    st.subheader("1. ç”»åƒã®é¸åˆ¥")
    st.caption("ä¸è¦ãªç”»åƒã®ãƒã‚§ãƒƒã‚¯ã‚’å¤–ã—ã¦ãã ã•ã„")

    # ç”»åƒé¸åˆ¥ã‚°ãƒªãƒƒãƒ‰
    imgs = raw['images']
    cols = st.columns(6) # 6åˆ—ã§è¡¨ç¤º
    selected_indices = []
    
    # ç”»åƒã”ã¨ã«ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’è¡¨ç¤º
    for i, img_url in enumerate(imgs):
        with cols[i % 6]:
            st.image(img_url, use_container_width=True)
            # keyã‚’ä¸€æ„ã«ã™ã‚‹
            is_checked = st.checkbox(f"ç”»åƒ {i+1}", value=(i in st.session_state.selected_image_indices), key=f"img_chk_{i}")
            if is_checked:
                selected_indices.append(i)
    
    # é¸æŠçŠ¶æ…‹ã‚’æ›´æ–°
    st.session_state.selected_image_indices = selected_indices
    final_images = [imgs[i] for i in selected_indices]

    st.markdown("---")
    st.subheader("2. å‡ºå“ãƒ‡ãƒ¼ã‚¿ç·¨é›† (æ‰‹å‡ºå“ãƒ¢ãƒ¼ãƒ‰)")
    
    # ç¿»è¨³ã¨è¨ˆç®— (åˆå›ã®ã¿å®Ÿè¡Œã•ã‚Œã‚‹ã‚ˆã†ã«ã—ãŸã„ãŒã€ã‚·ãƒ³ãƒ—ãƒ«ã•å„ªå…ˆã§æ¯å›è¨ˆç®—)
    title_en = translate_text(raw['title'])
    desc_en = translate_text(raw['description'][:800]) # é•·ã™ãé˜²æ­¢
    
    try:
        price_str = str(raw['price']).replace(',', '').replace('å††', '').replace('ï¿¥', '')
        price_jp = int(re.search(r'\d+', price_str).group())
        price_usd = (price_jp + target_profit) / usd_rate / (1 - ebay_fee_rate)
        price_usd = round(price_usd, 2)
    except:
        price_jp = 0
        price_usd = 0.00

    # --- å·¦å³åˆ†å‰²ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
    left_col, right_col = st.columns([1, 1])

    with left_col:
        st.info("ğŸ–¼ï¸ é¸ã‚“ã ç”»åƒ (ä¸Šã‹ã‚‰é †)")
        # é¸æŠã•ã‚ŒãŸç”»åƒã‚’ç¸¦ã«ä¸¦ã¹ã‚‹ï¼ˆãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã¯Streamlitæ¨™æº–ã§ã¯ä¸å¯ã ãŒã€ä¸€è¦§æ€§ã¯é«˜ã„ï¼‰
        for i, img_url in enumerate(final_images):
            st.image(img_url, width=300, caption=f"No.{i+1}")
            st.text_input(f"URL {i+1} (Copyç”¨)", value=img_url, key=f"url_copy_{i}")

    with right_col:
        st.info("ğŸ“ Item Specifics & è©³ç´°")
        
        with st.form("listing_form"):
            # åŸºæœ¬æƒ…å ±
            new_title = st.text_input("Title (80æ–‡å­—)", value=title_en, max_chars=80)
            new_price = st.number_input("Start Price ($)", value=price_usd)
            new_desc = st.text_area("Description (HTMLå¯)", value=desc_en, height=200)
            
            st.markdown("### Item Specifics")
            specifics_values = {}
            
            # ã‚«ãƒ†ã‚´ãƒªãƒ¼è¨­å®šã«åŸºã¥ã„ãŸå…¥åŠ›æ¬„ã‚’ç”Ÿæˆ
            for spec in cat_config["specifics"]:
                # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ãã‚Œã£ã½ã„å€¤ã‚’æ¨æ¸¬ã—ã¦åˆæœŸå€¤ã«å…¥ã‚Œã‚‹ï¼ˆç°¡æ˜“ç‰ˆï¼‰
                default_val = ""
                if spec == "Brand":
                    # ç°¡æ˜“ãƒ–ãƒ©ãƒ³ãƒ‰æ¤œçŸ¥
                    for b in ["Nike", "Adidas", "Sony", "Canon", "Nikon", "Shimano", "Daiwa", "Seiko", "Casio", "Nintendo", "Bandai"]:
                        if b.lower() in new_title.lower():
                            default_val = b
                            break
                
                specifics_values[spec] = st.text_input(spec, value=default_val)

            submitted = st.form_submit_button("ãƒªã‚¹ãƒˆã«è¿½åŠ  & CSVæº–å‚™")

            if submitted:
                # ä¿å­˜ç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆ
                item_data = {
                    "Action": "Add",
                    "Category": cat_config["id"],
                    "Title": new_title,
                    "StartPrice": new_price,
                    "Description": new_desc,
                    "ConditionID": "3000",
                    "PicURL": "|".join(final_images) # é¸æŠã•ã‚ŒãŸç”»åƒã®ã¿çµåˆ
                }
                # Specificsã‚’çµåˆ
                item_data.update(specifics_values)
                
                st.session_state.scraped_data_list.append(item_data)
                st.success("ãƒªã‚¹ãƒˆã«è¿½åŠ ã—ã¾ã—ãŸï¼")

# --- ãƒªã‚¹ãƒˆã¨CSVå‡ºåŠ› ---
st.markdown("---")
st.subheader(f"ğŸ“‚ å‡ºå“å¾…ã¡ãƒªã‚¹ãƒˆ ({len(st.session_state.scraped_data_list)}ä»¶)")

if st.session_state.scraped_data_list:
    df = pd.DataFrame(st.session_state.scraped_data_list)
    
    # å„ªå…ˆè¡¨ç¤ºã‚«ãƒ©ãƒ 
    priority_cols = ["Title", "StartPrice", "PicURL"] + cat_config["specifics"]
    # å­˜åœ¨ã—ãªã„ã‚«ãƒ©ãƒ ã‚’é™¤å¤–
    display_cols = [c for c in priority_cols if c in df.columns]
    
    st.dataframe(df[display_cols])
    
    csv = df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="ğŸ“¥ CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (eBay File Exchangeå½¢å¼)",
        data=csv,
        file_name='ebay_listing_final.csv',
        mime='text/csv',
    )
