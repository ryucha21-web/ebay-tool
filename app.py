import streamlit as st
import asyncio
import sys
import subprocess
import pandas as pd
import re

# --- ãƒ–ãƒ©ã‚¦ã‚¶ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å‡¦ç† ---
def install_playwright_browser():
    try:
        import os
        subprocess.run([sys.executable, "-m", "playwright", "install", "chromium"], check=True)
    except Exception as e:
        print(f"Error installing browser: {e}")

install_playwright_browser()

from playwright.async_api import async_playwright
from deep_translator import GoogleTranslator

# --- Windowså¯¾ç­– ---
if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if 'scraped_data_list' not in st.session_state:
    st.session_state.scraped_data_list = []

# --- é–¢æ•°ç¾¤ ---

def translate_text(text):
    try:
        return GoogleTranslator(source='ja', target='en').translate(text)
    except:
        return text

def extract_hobby_brand(text):
    brands = [
        "Bandai", "Banpresto", "Nintendo", "Sony", "Sega", "Pokemon", 
        "Sanrio", "Konami", "Takara Tomy", "Good Smile Company", 
        "Kotobukiya", "Tamiya", "Square Enix", "Capcom", "Funko", "Lego"
    ]
    text_lower = text.lower()
    for brand in brands:
        if brand.lower() in text_lower:
            return brand
    return "Unbranded"

def guess_type(text):
    text_lower = text.lower()
    if "figure" in text_lower or "ãƒ•ã‚£ã‚®ãƒ¥ã‚¢" in text_lower:
        return "Action Figure"
    elif "plush" in text_lower or "ã¬ã„ãã‚‹ã¿" in text_lower or "doll" in text_lower:
        return "Plush"
    elif "card" in text_lower or "tcg" in text_lower:
        return "Trading Card"
    elif "game" in text_lower or "console" in text_lower:
        return "Video Game"
    else:
        return "Action Figure"

# --- ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†ï¼ˆURLãƒ‘ã‚¿ãƒ¼ãƒ³ãƒžãƒƒãƒãƒ³ã‚°ç‰ˆï¼‰ ---
async def scrape_data(url):
    async with async_playwright() as p:
        # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰è¨­å®š
        browser = await p.chromium.launch(headless=True, args=['--no-sandbox', '--disable-setuid-sandbox'])
        page = await browser.new_page()
        try:
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã‚’é•·ã‚ã«
            await page.goto(url, timeout=60000)
            
            # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å®Œäº†ã‚’å¾…ã¤ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®é™å¯‚ã‚’å¾…ã¤ï¼‰
            try:
                await page.wait_for_load_state("networkidle", timeout=10000)
            except:
                pass # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¦ã‚‚é€²ã‚€
            
            # å°‘ã—å¾…æ©Ÿï¼ˆç”»åƒã®é…å»¶èª­ã¿è¾¼ã¿å¯¾ç­–ï¼‰
            await page.wait_for_timeout(3000)

            # --- ç”»åƒå–å¾—ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆæœ€å¼·ç‰ˆï¼‰ ---
            # ãƒšãƒ¼ã‚¸å†…ã®ã™ã¹ã¦ã®ã€Œimgã€ã‚¿ã‚°ã‚’å–å¾—
            images_elements = await page.locator("img").all()
            
            image_urls = []
            seen_urls = set() # é‡è¤‡é˜²æ­¢ç”¨

            for img in images_elements:
                src = await img.get_attribute("src")
                if src:
                    # ãƒ¡ãƒ«ã‚«ãƒªã®å•†å“ç”»åƒURLãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    # "static.mercdn.net/item/detail/orig/photos/" ãŒå•†å“ç”»åƒã®è¨¼
                    if "static.mercdn.net/item/detail/orig/photos/" in src:
                        # ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿(?ä»¥é™)ã‚’å‰Šé™¤ã—ã¦ãã‚Œã„ãªURLã«ã™ã‚‹
                        clean_url = src.split('?')[0]
                        
                        if clean_url not in seen_urls:
                            image_urls.append(clean_url)
                            seen_urls.add(clean_url)
            
            # ç”»åƒãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if not image_urls:
                meta_img = page.locator("meta[property='og:image']")
                if await meta_img.count() > 0:
                    src = await meta_img.get_attribute("content")
                    image_urls.append(src)

            # åŸºæœ¬æƒ…å ±å–å¾—
            title_el = page.locator("h1").first
            title = await title_el.inner_text() if await title_el.count() > 0 else "å–å¾—å¤±æ•—"
            
            price = "0"
            # ä¾¡æ ¼ã‚»ãƒ¬ã‚¯ã‚¿ã‚‚å¿µã®ãŸã‚è¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ç”¨æ„
            if await page.locator("[data-testid='price']").count() > 0:
                price = await page.locator("[data-testid='price']").first.inner_text()
            elif await page.locator(".item-price-box").count() > 0:
                price = await page.locator(".item-price-box").first.inner_text()
            
            desc = ""
            if await page.locator("[data-testid='description']").count() > 0:
                desc = await page.locator("[data-testid='description']").first.inner_text()

            return {
                "title": title, 
                "price": price, 
                "description": desc, 
                "images": image_urls
            }
        except Exception as e:
            return {"error": str(e)}
        finally:
            await browser.close()

# --- ç”»é¢UI ---
st.set_page_config(layout="wide")
st.title("eBayå‡ºå“ãƒ„ãƒ¼ãƒ« (å…¨ç”»åƒå–å¾—ãƒ»æœ€å¼·ç‰ˆ)")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.header("è¨­å®š")
usd_rate = st.sidebar.number_input("ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆ (1ãƒ‰ãƒ«=ã€‡ã€‡å††)", value=150)
target_profit = st.sidebar.number_input("ç›®æ¨™åˆ©ç›Š (å††)", value=2000)
ebay_fee_rate = 0.15 

url = st.text_input("ãƒ¡ãƒ«ã‚«ãƒªã®å•†å“URL", "")

if st.button("æƒ…å ±ã‚’å–å¾—ã—ã¦å¤‰æ›"):
    if not url:
        st.warning("URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        with st.spinner('å…¨ç”»åƒã‚’è§£æžä¸­...'):
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            data = loop.run_until_complete(scrape_data(url))
            loop.close()
            
            if "error" in data:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {data['error']}")
            else:
                title_en = translate_text(data['title'])
                desc_en = translate_text(data['description'][:500])
                brand_val = extract_hobby_brand(title_en + " " + data['title'])
                type_val = guess_type(title_en + " " + data['title'])
                
                try:
                    price_jp = int(re.sub(r'[^\d]', '', data['price']))
                    price_usd = (price_jp + target_profit) / usd_rate / (1 - ebay_fee_rate)
                    price_usd = round(price_usd, 2)
                except:
                    price_jp = 0
                    price_usd = 0.00

                pic_url_str = "|".join(data['images'])

                st.session_state.current_data = {
                    "Action": "Add",
                    "Category": "246", 
                    "Title": title_en,
                    "StartPrice": price_usd,
                    "ConditionID": "3000",
                    "Description": desc_en,
                    "PicURL": pic_url_str,
                    "Brand": brand_val,
                    "Type": type_val,
                    "Franchise": "",
                    "Character": "",
                }
                
                col1, col2 = st.columns([1, 1])
                
                with col1:
                    st.subheader(f"ðŸ“¸ å–å¾—ç”»åƒ ({len(data['images'])}æžš)")
                    # å–å¾—é †ã«ç•ªå·ã‚’æŒ¯ã£ã¦è¡¨ç¤º
                    if data['images']:
                        cols = st.columns(4)
                        for i, img_url in enumerate(data['images'][:8]): # æœ€å¤§8æžšãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                            with cols[i % 4]:
                                st.image(img_url, caption=f"No.{i+1}", use_container_width=True)
                        if len(data['images']) > 8:
                            st.caption(f"...ä»– {len(data['images'])-8} æžš")
                    
                    st.write(f"ðŸ‡¯ðŸ‡µ ä»•å…¥: Â¥{price_jp}")
                    st.caption(data['title'])
                
                with col2:
                    st.subheader("ðŸ‡ºðŸ‡¸ å‡ºå“ãƒ‡ãƒ¼ã‚¿ç¢ºèª")
                    st.success(f"å‡ºå“ä¾¡æ ¼: ${price_usd}")
                    st.info("Item Specificsã‚’å…¥åŠ›ã—ã¦ãƒªã‚¹ãƒˆã«è¿½åŠ ã—ã¦ãã ã•ã„")

# ãƒ•ã‚©ãƒ¼ãƒ ã‚¨ãƒªã‚¢
if 'current_data' in st.session_state:
    st.markdown("---")
    with st.form("edit_form"):
        c_data = st.session_state.current_data
        
        col_a, col_b = st.columns([3, 1])
        new_title = col_a.text_input("Title", c_data['Title'], max_chars=80)
        new_price = col_b.number_input("Price ($)", value=c_data['StartPrice'])
        
        st.caption("Required Item Specifics")
        r1, r2 = st.columns(2)
        new_franchise = r1.text_input("Franchise (ä½œå“å)", c_data['Franchise'])
        new_character = r2.text_input("Character (ã‚­ãƒ£ãƒ©å)", c_data['Character'])
        
        r3, r4 = st.columns(2)
        new_brand = r3.text_input("Brand", c_data['Brand'])
        new_type = r4.text_input("Type", c_data['Type'])

        submitted = st.form_submit_button("ãƒªã‚¹ãƒˆã«è¿½åŠ ã™ã‚‹")
        
        if submitted:
            c_data['Title'] = new_title
            c_data['StartPrice'] = new_price
            c_data['Brand'] = new_brand
            c_data['Franchise'] = new_franchise
            c_data['Character'] = new_character
            c_data['Type'] = new_type
            
            st.session_state.scraped_data_list.append(c_data)
            st.success(f"âœ… è¿½åŠ ã—ã¾ã—ãŸï¼ï¼ˆç”»åƒæ•°: {len(c_data['PicURL'].split('|'))}æžšï¼‰")

# ãƒªã‚¹ãƒˆè¡¨ç¤ºã‚¨ãƒªã‚¢
st.markdown("---")
st.subheader(f"ðŸ“‚ å‡ºå“å¾…ã¡ãƒªã‚¹ãƒˆ ({len(st.session_state.scraped_data_list)}ä»¶)")

if st.session_state.scraped_data_list:
    df = pd.DataFrame(st.session_state.scraped_data_list)
    
    display_df = df.copy()
    display_df['PicURL'] = display_df['PicURL'].apply(lambda x: x[:30] + "..." if len(x) > 30 else x)
    
    st.dataframe(display_df)
    
    csv = df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="ðŸ“¥ CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (eBayç”¨)",
        data=csv,
        file_name='ebay_collectibles_full_images.csv',
        mime='text/csv',
    )
